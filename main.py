
import logging
import os
from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
from dotenv import load_dotenv
import openai

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot)

SYSTEM_PROMPT = Path("prompt.txt").read_text()

@dp.message_handler(commands=["start"])
async def start_handler(message: types.Message):
    user_text = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ–ª—å–∫–æ —á—Ç–æ –Ω–∞–∂–∞–ª /start. –ü–æ–∑–¥–æ—Ä–æ–≤–∞–π—Å—è, –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Å—è, –ø—Ä–∏–≥–ª–∞—Å–∏ –∫ –¥–∏–∞–ª–æ–≥—É, –ø–æ–¥—á–µ—Ä–∫–Ω–∏ –∞–Ω–æ–Ω–∏–º–Ω–æ—Å—Ç—å."
    reply = await generate_reply(user_text)
    await message.answer(reply)

@dp.message_handler()
async def message_handler(message: types.Message):
    reply = await generate_reply(message.text)
    await message.answer(reply)

async def generate_reply(user_message: str) -> str:
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_message}
            ]
        )
        return response.choices[0].message["content"]
    except Exception as e:
        return "–ü—Ä–æ—Å—Ç–∏, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ üôè"

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    executor.start_polling(dp, skip_updates=True)
